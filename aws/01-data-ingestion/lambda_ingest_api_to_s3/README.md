[![English](https://img.shields.io/badge/lang-en-blue.svg)](README.md)
[![PortuguÃªs](https://img.shields.io/badge/lang-pt--br-green.svg)](README.pt-br.md)

# Lambda - API to S3 Ingestion (Batch)

> Part of the `01-data-ingestion` module from the DataOps specialization on AWS.

---

## ðŸ“Œ Objective

Create a scheduled batch Lambda function to:

- Fetch data from a public API  
- Store raw data in Amazon S3  
- Organize files by date (`YYYY/MM/DD`)  
- Automate deployment with GitHub Actions  

---

## ðŸ§° Technologies and Services Used

- AWS Lambda (Python)  
- Amazon S3  
- EC2 + Airflow (scheduling)  
- AWS CloudWatch (logs)  
- GitHub Actions (CI/CD)  
- Terraform (infrastructure as code)  

---

## ðŸ§± Project Structure

```bash
lambda_ingest_api_to_s3/
â”œâ”€â”€ lambda/                        # Python code for the Lambda function
â”‚   â””â”€â”€ handler.py
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ deploy_lambda.yml          # GitHub Actions pipeline
â”œâ”€â”€ terraform/
â”‚   â””â”€â”€ main.tf                    # Infrastructure for the function and S3
â”œâ”€â”€ deploy.sh                      # Local deployment script (manual)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
